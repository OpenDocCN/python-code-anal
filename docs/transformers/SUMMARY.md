+   [Tranformers 架构和源码解析](README.md)
+   [AttentionFreeTransformer 源码解析（一）：AFTFull、AFTSimple、AFTLocal-CSDN博客](AttentionFreeTransformer-AFTFull-AFTSimple-AFTLocal.md)
+   [Bert Pytorch 源码分析：二、注意力层_绝不原创的飞龙的博客-CSDN博客](Bert-Pytorch-Attention.md)
+   [Bert PyTorch 源码分析：一、嵌入层-CSDN博客](Bert-PyTorch-Embedding.md)
+   [Bert Pytorch 源码分析：四、编解码器_绝不原创的飞龙的博客-CSDN博客](Bert-Pytorch-Encoder.md)
+   [Bert Pytorch 源码分析：三、Transformer块_绝不原创的飞龙的博客-CSDN博客](Bert-Pytorch-TFBlock.md)
+   [Bert Pytorch 源码分析：五、模型架构简图 REV1_绝不原创的飞龙的博客-CSDN博客](Bert-Pytorch.md)
+   [ChatGLM2 源码分析：`ChatGLMForConditionalGeneration.chat, .stream_chat`_绝不原创的飞龙的博客-CSDN博客](ChatGLM2-ChatGLMForConditionalGeneration.chat-stream_chat.md)
+   [ChatGLM2 源码解析：`ChatGLMForConditionalGeneration.forward`-CSDN博客](ChatGLM2-ChatGLMForConditionalGeneration.forward.md)
+   [ChatGLM2 源码解析：`ChatGLMModel`_绝不原创的飞龙的博客-CSDN博客](ChatGLM2-ChatGLMModel.md)
+   [ChatGLM2 源码解析：`GLMBlock`-CSDN博客](ChatGLM2-GLMBlock.md)
+   [ChatGLM2 源码解析：`GLMTransformer`-CSDN博客](ChatGLM2-GLMTransformer.md)
+   [ChatGLM2 源码解析：`MLP`_绝不原创的飞龙的博客-CSDN博客](ChatGLM2-MLP.md)
+   [KVCache原理简述-CSDN博客](KVCache.md)
+   [VisionTransformer（ViT）详细架构图-CSDN博客](VisionTransformer.md)
+   [Whisper 整体架构图](Whisper.md)